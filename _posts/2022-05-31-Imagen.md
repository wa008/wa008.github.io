---
layout: default
title: Imagen
---

# 背景
[Imagen](https://imagen.research.google/) 是谷歌做的一个输入文本，自动生成对应图片的工具，突然看到 Imagen 的宣传，感觉 UGC 离现实生活越来越近了。
<img src="/images/2022/05/457684880.png" width="500" alt="">

之前 GPT-3 生成的[一篇文章](https://news.ycombinator.com/item?id=23893817)登顶 hacknews，引发一波热潮，但总觉得文本的 UGC 落地感觉还比较难，因为文本的理解成本高，审核成本高，但图像，是一个生成成本高、理解成本低的内容，特别是在视频横行的现在，现在生成成本可以让模型自动化来做了，落地应该也不远了。
机器自动生成文本或许不能完全替代摄影师，但应该还是会抢一些摄影社的饭碗，普通网民应该是没办法区分图片是自动生成的还是真人拍摄的，自动生成的效率一定比真人拍摄高，长久以往，网上大量的图片可能都是机器生成的了。
或许过几天就会有个 text-to-video 的论文出来。

# 论文
### 文本表征
通过语言模型将本文信息用 Embedding 表征，论文中用冻结的 T5 来做文本理解和表征。
作者发现提升 LM 的复杂度，相比提升扩散模型的复杂度能给 text-to-iamge 任务带来更多提升，说明该任务的瓶颈在于文本理解，也从一定角度说明文本理解还有一些提升空间。
### 扩散模型
利用扩散模型将 Embedding 生成为图像，进一步提升清晰度，输出结果。
扩散模型跟大名鼎鼎的 GAN 同属于生成网络，通过N步迭代，每一步以特定高斯分布采样噪音，添加到原始图像上，使其逐步变为 Embedding 隐变量，训练参数主要是生成噪音的正态分布的均值和方差。
原文还提出动态阈值的方法提升图片的真实度和清晰度；提出更简单高效的扩散模型结构 Efficient U-Net；在已有评测数据上达到 sota；提出新的评测数据。
出于安全和滥用的考虑，谷歌没有对外开源代码和模型工具。

# 参考
https://www.zhaoyabo.com/?p=7675
https://arxiv.org/abs/2205.11487