
这几个看的比较糙，就写到一起了。
# Functional Decomposition 函数分解
把模型做因式分解

$$ f(x1, x2, x3) = f(0) + f(x1) + f(x2) + f(x3) + f(x1, x2) + f(x1, x3) + f(x2, x3) + f(x1, x2, x3) $$

尽量拆解变量之间的关系，进行简化。方案比较理想。

# Permutation Feature Importance
删除一个特征，看模型预测值的变化，来衡量特征重要性
用训练集还是测试集实验呢？测试集
1. 如果用训练集：模型过拟合的话，训练集上也会显示误差较大，会误以为特征比较重要。
2. 如果用测试集：优点是，特征即使和预测值没有线性关心，只要被用到，依然会表现出合理的重要性取值。

优点
1. 好理解，解释性强。
2. 有全局视角
3. 耗时短：不需要重训模型，重训对比的是不同的模型，而我们想解释的应该是当前的模型，不应该重训。

缺点
1. 优点3是优点也是缺点，要看具体的应用场景。如果目标只是纯粹衡量特征的好快，与模型无关，那此方法就不合适。
2. 当模型预测结果和 ground truth 差别较大是，误差大可能更优，误差大就可能代表不了特征不重要。
3. 对相关性强的特征很不友好。比如两个身高和体重，可能都能衡量人的体型大小，但具体哪个特征重要，取决于模型使用了哪个特征，这个缺点在树模型中更加显著。

# Global Surrogate
描述：训练一个可解释的模型去拟合原模型，通过解释「可解释模型」来解释原模型。
看法：在原模型不可变的情况下比较适用。比如线上模型出故障了排查原因、线上模型由于各种原因不能修改。

# Prototypes and Criticisms
描述：挑选原数据集中具有代表性的点（Prototypes），再挑选Prototypes 代表的不好的点Criticisms，利用这些代表点来解释模型，看是否被模型正确判定。
看法：
1. 是一个从数据角度解释的方式，并不是解释模型。
2. 选点比较类似聚类

参考：https://christophm.github.io/interpretable-ml-book/global-methods.html
