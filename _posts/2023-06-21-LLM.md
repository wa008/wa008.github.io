---
layout: default
title: 大模型调研
---

# 背景

ChatGPT 2022.11 月问世之后引起的轰动一直在上升，但类似的做法和能力，在bert 2018年出现的时候基本就有了，一般认为 ChatGPT 的出现，是大模型大到一定程度后，能容纳的知识更加丰富，能力产生了质变，能应用几乎所有的对话类任务。

ChatGPT的训练成本过高，传言预训练一次需要200w美金，这应该也是openai 能在这个领域一骑绝尘的原因，并不是每个公司都有眼光和胆魄愿意花费这么大成本训练一个模型。

# 调研

如此大的模型和高昂的训练成本，使个人很难低成本参与进去，圈内玩家基本是各个巨头公司。但偶发发现最近开了一大批大模型相关的项目，就调研看了看。

### 开源/公开

[Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT): 用户输入目标，Auto-GPT 利用 ChatGPT 生成一个机器人，利用各种prompt让GPT理解用户输入的目标，制作能实现目标的计划，一步步实施。本质还是用 prompt 扩展 ChatGPT 的使用边界。

[Open-Assistant](https://github.com/LAION-AI/Open-Assistant): 开源大模型，通过用户收集高质量数据，来微调模型

[AgentGPT](https://github.com/reworkd/AgentGPT): Auto-GPT 的界面版本，让普通用户能更直接使用

[llama](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/): mate 公开 llama 65B 预训练模型，可用于研究，不可用于商业使用；给大模型的开源届提供了基石

[stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca): 斯坦福基于mate公开的大模型微调出的语言模型，命名为羊驼

[lm-sys FastChat](https://github.com/lm-sys/FastChat): lm-sys 参考羊驼训练的语言模型，效果逼近ChatGPT，最小的7B版本可以在单卡 28G显存的卡上微调

[Lm-sys score borad](https://chat.lmsys.org/?leaderboard): lm-sys 大语言模型榜单，模型对比竞技场

### 非公开

[ChatGPT](https://openai.com/blog/chatgpt): ChatGPT 发布

[ChatGPT plugins](https://openai.com/blog/chatgpt-plugins): 插件，丰富AI生态

[GPT4](https://openai.com/gpt-4): GPT4 发布，吊打各大榜单

[Claude](https://www.anthropic.com/index/introducing-claude): openAI 原班人马创业训练的大模型，是目前最逼近GPT4效果的模型

# 不足

[6个月暂定大模型研究](https://futureoflife.org/open-letter/pause-giant-ai-experiments/): 大模型发展太快，相应的风险措施跟不上，开始呼吁暂停大模型的研究

无法避免大模型胡说八道：模型的预训练方式应该还是基于自回归，模型架构是 transformer，更多利用的还是基于语言的统计信息，逻辑推理能力较弱；简言之，大模型知识储备虽然吊打1000个人，但它输出的准确性并不是100%

[现在的大模型架构无法支持走向AGI](https://twitter.com/ylecun/status/1667947166764023808)：现在大模型的归因和规划能力（逻辑能力）还不够，不足以走向AGI（强人工智能）

如果让大模型可控、安全

# 结论

大模型现在未解决的主要问题就是 逻辑能力，如果大模型已有的架构能解决此问题，那就直接实现了AGI。否则 AGI 需要另外一种新的架构，我个人稍微倾向于后者。

基于多个原因，我暂时还是看看我的自动驾驶项目吧

1. 大模型需要的GPU门槛稍高，反正我现在没有；借用公司的也不太好
2. 对大模型并没有什么idea要尝试；代码层面的改动也比较少
3. 大模型缺乏逻辑能力，很难走向AGI
4. 强化学习才是走向AGI的必经之路！
